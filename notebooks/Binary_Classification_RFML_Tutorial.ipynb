{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5859930",
   "metadata": {},
   "source": [
    "# Binary Classification Tutorial\n",
    "This notebook demonstrates how to train and test a binary classifier.  The binary classification problem is to determine if a signal is BPSK or QPSK using a simple CNN-based classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2c7edd",
   "metadata": {},
   "source": [
    "## Load Packages\n",
    "Load packages that will be used throughout this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d0d2e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "# General python packages\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# metrics from sci-kit learn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# pytorch packages\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "\n",
    "# custom tutorial packages\n",
    "from rfml_ed_material.utils.data_utils import IQ_Dataset, IQ_data_gen, create_signal_jsons\n",
    "from rfml_ed_material.models.cnn_model import CNN_RF\n",
    "from rfml_ed_material.utils.train_utils import train_func, predict_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a1667b",
   "metadata": {},
   "source": [
    "## Data Generation Parameters\n",
    "Define the data generation parameters for Py-waspgen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ba9d64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_seq = 5000        # number of sequences per signal type\n",
    "seq_len = 256         # length of each sequence\n",
    "bandwidth = 0.5       # bandwidth\n",
    "cent_freq = 0.0       # center frequency\n",
    "start = 0             # signal start time\n",
    "duration = seq_len    # signal duration\n",
    "snr = 10              # signal to noise ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d985d1",
   "metadata": {},
   "source": [
    "Define the signal types in the form of a list - BPSK and QPSK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2493f94a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "signal_list = [{\"format\": \"psk\", \"order\": 2, \"label\": \"BPSK\"},\n",
    "               {\"format\": \"psk\", \"order\": 4, \"label\": \"QPSK\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a906581f",
   "metadata": {},
   "source": [
    "Py-waspgen loads configuration information from json files.  Use the *create_signal_jsons* function to create the py-waspgen configuration files.\n",
    "\n",
    "The following cell first checks if the \"Configs'' directory exists and, if it does not, it creates the directory for storing the json configuration files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f0a88c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir('configs'):\n",
    "    os.mkdir('configs')\n",
    "\n",
    "create_signal_jsons('configs',\n",
    "                    signal_list,\n",
    "                    observation_duration=seq_len,\n",
    "                    cent_freq=[cent_freq, cent_freq],\n",
    "                    bandwidth=[bandwidth, bandwidth],\n",
    "                    start=[start, start],\n",
    "                    duration=[seq_len, seq_len],\n",
    "                    snr=[snr, snr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935b2cad",
   "metadata": {},
   "source": [
    "## Generate Data\n",
    "Use py-waspgen to generate data for training, validation, and testing a binary classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c4bb0c",
   "metadata": {},
   "source": [
    "Create the list of configuration files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499e424e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "signal_filenames = ['configs/BPSK.json', 'configs/QPSK.json']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715e4001",
   "metadata": {},
   "source": [
    "Generate data using wrapper function from *data_utils*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05997413",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data, labels, label_dict = IQ_data_gen(signal_filenames, num_seq, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee45aa9",
   "metadata": {},
   "source": [
    "## Prepare Data for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddb676e",
   "metadata": {},
   "source": [
    "Pytorch uses a data set class for the data.  See the pytorch documentation for more details.\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef0dfe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_dataset = IQ_Dataset(data, labels, label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24592dee",
   "metadata": {},
   "source": [
    "The data set should be split into training, validation, and testing sets.  The training set is used to train the model.  The validation set is used to track the model's performance during training and monitor for overfitting.  The test set is used for final evaluation of the model.  \n",
    "\n",
    "The cell below uses the *random_split* pytorch function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a5fae0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "splits = [0.8, 0.1, 0.1]   # proportion for train, validation, and test sets\n",
    "rf_train, rf_val, rf_test = random_split(rf_dataset, splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94a81c8",
   "metadata": {},
   "source": [
    "Pytorch uses data loaders to batch the data.  The cell below sets the batch size parameter and creates dataloaders for the training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43d4eb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 256           # batch size for dataloader\n",
    "\n",
    "# create dataloader\n",
    "train_dataloader = DataLoader(rf_train, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(rf_val, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(rf_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff353648",
   "metadata": {},
   "source": [
    "## Train Pytorch Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ccac3c",
   "metadata": {},
   "source": [
    "Establish the Pytorch CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68f0d67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CNN_RF(len(signal_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2dfb61",
   "metadata": {},
   "source": [
    "Set the learning rate for the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e9b45c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001  # learning rate for optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c49f3",
   "metadata": {},
   "source": [
    "Define the loss function and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a7610c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb41766",
   "metadata": {},
   "source": [
    "Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaa5dbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 200        # number of training epochs\n",
    "print_every_n = 10  # print loss every n epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6107c8ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, train_loss, val_loss = train_func(model,\n",
    "                                         optimizer,\n",
    "                                         loss_fn,\n",
    "                                         train_dataloader,\n",
    "                                         val_dataloader,\n",
    "                                         epochs,\n",
    "                                         print_every_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e7b43c",
   "metadata": {},
   "source": [
    "## Evaluate Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df121b91",
   "metadata": {},
   "source": [
    "Plot training and validation loss. This should be done after training or monitored during training.  This confirms that the model learning has stablized and that the model is not overfit.  The latter can be seen because the validation loss is not increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39795327",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(train_loss, color='b', label=\"Train\")\n",
    "ax.plot(val_loss, color='r', label=\"Validation\")\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Training and Validation Loss')\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8259e04",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5b2ca9",
   "metadata": {},
   "source": [
    "Use the custom *predict_func* to extract the true targets from the test data loader and the predicted values for the test set from the learned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058386bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test, y_pred = predict_func(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe1aae8",
   "metadata": {},
   "source": [
    "When evaluating binary classifiers, there are four possible combinations of true and predicted values for each observation.\n",
    "These are displayed in the table below.\n",
    "\n",
    "<img src=\"resources/binary_classification_results.png\" width=\"600\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925fd541",
   "metadata": {},
   "source": [
    "During evaluation, one can count the number of combinations in each quadrant of the table.  Numerous performance metrics can be calculated from the counts in this table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e661670",
   "metadata": {},
   "source": [
    "Accuracy is the sum of the diagonal divided by the sum in all four quadrants.\n",
    "\n",
    "$$ Accuracy = \\frac{TP}{TP + FP + TN + FN} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5863bfa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d49b923",
   "metadata": {},
   "source": [
    "Precision measures the rate at which observations classified by the model as Postive are correct.  It is calculated by dividing the number of true positives by the sum of the true positives and false positives (all Positive examples classified by the model).\n",
    "\n",
    "$$ Precision = \\frac{TP}{TP + FP} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850c382a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision: ', precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99075749",
   "metadata": {},
   "source": [
    "Recall measures the rate at which relevant (Postive) observations are classified by the model as Positive.  It is calculated by dividing the number of true positives by the sum of the true positives and false negatives (all Postive examples in the test set).\n",
    "\n",
    "$$ Recall = \\frac{TP}{TP + FN} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c10339",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall: ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3903aa48",
   "metadata": {},
   "source": [
    "The F1 score is a combination of precision and recall.  \n",
    "\n",
    "$$ F1 = 2 \\frac{precision * recall}{precision+recall} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d58fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1: ', f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
