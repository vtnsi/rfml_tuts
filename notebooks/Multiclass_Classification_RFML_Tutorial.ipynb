{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5859930",
   "metadata": {},
   "source": [
    "# Multiclass Classification Tutorial\n",
    "This notebook demonstrates how to train and test a multi-class classifier.  The classification problem is to determine if a signal is one of 4 possible singals using a CNN-based classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2c7edd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Load Packages\n",
    "Load packages that will be used throughout this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d0d2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "# General python packages\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# metrics from sci-kit learn\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, precision_recall_fscore_support\n",
    "\n",
    "# pytorch packages\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "\n",
    "# custom tutorial packages\n",
    "from rfml_ed_material.utils.data_utils import IQ_Dataset, IQ_data_gen, create_signal_jsons\n",
    "from rfml_ed_material.models.cnn_model import CNN_RF\n",
    "from rfml_ed_material.utils.train_utils import train_func, predict_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a1667b",
   "metadata": {},
   "source": [
    "## Data Generation Parameters\n",
    "Data generation parameters for Py-waspgen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6e4764",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seq = 5000        # number of sequences per signal type\n",
    "seq_len = 256         # length of each sequence\n",
    "bandwidth = 0.5       # bandwidth\n",
    "cent_freq = 0.0       # center frequency\n",
    "start = 0             # signal start time\n",
    "duration = seq_len    # signal duration\n",
    "snr = 10              # signal to noise ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56b82db",
   "metadata": {},
   "source": [
    "Define the signal types in the form of a list - BPSK and QPSK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f255f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of 4 signals\n",
    "signal_list = [{\"format\": \"ask\", \"order\": 16, \"label\": \"16ASK\"},\n",
    "               {\"format\": \"pam\", \"order\": 16, \"label\": \"16PAM\"},\n",
    "               {\"format\": \"psk\", \"order\": 16, \"label\": \"16PSK\"},\n",
    "               {\"format\": \"qam\", \"order\": 16, \"label\": \"16QAM\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04119a27",
   "metadata": {},
   "source": [
    "Py-waspgen loads configuration information from json files.  Use the *create_signal_jsons* function to create the py-waspgen configuration files.\n",
    "\n",
    "The following cell first checks if the \"configs'' directory exists and, if it does not, it creates the directory for storing the json configuration files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd20634",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('configs'):\n",
    "    os.mkdir('configs')\n",
    "\n",
    "create_signal_jsons('configs',\n",
    "                    signal_list,\n",
    "                    observation_duration=seq_len,\n",
    "                    cent_freq=[cent_freq, cent_freq],\n",
    "                    bandwidth=[bandwidth, bandwidth],\n",
    "                    start=[start, start],\n",
    "                    duration=[seq_len, seq_len],\n",
    "                    snr=[snr, snr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935b2cad",
   "metadata": {},
   "source": [
    "## Generate Data\n",
    "Use py-waspgen to generate data for training, validation, and testing a multiclass classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c4bb0c",
   "metadata": {},
   "source": [
    "Create the list of configuration files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499e424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_filenames = ['configs/' + signal[\"label\"] + '.json' for signal in signal_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715e4001",
   "metadata": {},
   "source": [
    "Generate data using wrapper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05997413",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels, label_dict = IQ_data_gen(signal_filenames, num_seq, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee45aa9",
   "metadata": {},
   "source": [
    "## Prepare Data for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24592dee",
   "metadata": {},
   "source": [
    "Pytorch uses a data set class for the data.  See the pytorch documentation for more details.\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef0dfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset class\n",
    "rf_dataset = IQ_Dataset(data, labels, label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43370121",
   "metadata": {},
   "source": [
    "The data set should be split into training, validation, and testing sets.  The training set is used to train the model.  The validation set is used to track the model's performance during training and monitor for overfitting.  The test set is used for final evaluation of the model.  \n",
    "\n",
    "The cell below uses the *random_split* pytorch function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a5fae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [0.8, 0.1, 0.1]  # proportion for train, validation, and test sets\n",
    "\n",
    "rf_train, rf_val, rf_test = random_split(rf_dataset, splits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69459b91",
   "metadata": {},
   "source": [
    "Pytorch uses data loaders to batch the data.  The cell below sets the batch size parameter and creates dataloaders for the training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43d4eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256           # batch size for dataloader\n",
    "\n",
    "# create dataloader\n",
    "train_dataloader = DataLoader(rf_train, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(rf_val, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(rf_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff353648",
   "metadata": {},
   "source": [
    "## Train Pytorch Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e198c7ff",
   "metadata": {},
   "source": [
    "Establish the Pytorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc5f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_RF(len(signal_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2dfb61",
   "metadata": {},
   "source": [
    "Set the learning rate for the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e9b45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001  # learning rate for optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cad1e9",
   "metadata": {},
   "source": [
    "Define the loss function and setup the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a7610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb41766",
   "metadata": {},
   "source": [
    "Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaa5dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200        # number of training epochs\n",
    "print_every_n = 10  # print loss every n epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6107c8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_loss, val_loss = train_func(model,\n",
    "                                         optimizer,\n",
    "                                         loss_fn,\n",
    "                                         train_dataloader,\n",
    "                                         val_dataloader,\n",
    "                                         epochs,\n",
    "                                         print_every_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e7b43c",
   "metadata": {},
   "source": [
    "## Evaluate Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df121b91",
   "metadata": {},
   "source": [
    "Plot training and validation loss. This should be done after training or monitored during training.  This confirms that the model learning has stablized and that the model is not overfit.  The latter can be seen because the validation loss is not increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39795327",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(train_loss, color='b', label=\"Train\")\n",
    "ax.plot(val_loss, color='r', label=\"Validation\")\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Training and Validation Loss')\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8259e04",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e74c37",
   "metadata": {},
   "source": [
    "Use the custom *predict_func* to extract the true targets from the test data loader and the predicted values for the test set from the learned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058386bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test, y_pred = predict_func(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b2dd32",
   "metadata": {},
   "source": [
    "Display the confusion matrix for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeee031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [signal[\"label\"] for signal in signal_list]\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=labels, xticks_rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a30dab7",
   "metadata": {},
   "source": [
    "Calculate the accuracy of the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5863bfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e212e9",
   "metadata": {},
   "source": [
    "For multiclass probelms, metrics such as precision, recall, and f1 score must be calculated per class.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad6dd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fscore, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "print('Precision for each class: ', precision)\n",
    "print('Recall for each class: ', recall)\n",
    "print('F1 score for each class: ', fscore)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
